{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit card detection for Fraud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Datasets/creditcard.csv\")\n",
    "display(data.head())\n",
    "display(data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "data[\"Amount\"] = sc.fit_transform(pd.DataFrame(data[\"Amount\"]))\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "dataframe = data.drop_duplicates()\n",
    "print(data.shape)\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.countplot(data=dataframe[\"Class\"]) WAY too slow to create\n",
    "dataframe[\"Class\"].value_counts().plot.bar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Class\",axis = 1)\n",
    "y = data[\"Class\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Logistic Regression========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamiroscreti/anaconda3/envs/Portfolio/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.9989115550718023\n",
      "\n",
      " Precision: 0.7045454545454546\n",
      "\n",
      " Recall: 0.6326530612244898\n",
      "\n",
      " F1: 0.6666666666666666\n",
      "\n",
      "======Decision Tree Classifier========\n",
      "\n",
      " Accuracy: 0.9991222218320986\n",
      "\n",
      " Precision: 0.7222222222222222\n",
      "\n",
      " Recall: 0.7959183673469388\n",
      "\n",
      " F1: 0.7572815533980582\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\" : LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n======{name}========\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n Recall: {recall_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n F1: {f1_score(y_test,y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling dataset cause too large and REALLY skewed towards 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = data[data['Class']==0]\n",
    "fraud = data[data['Class']==1]\n",
    "normal.shape\n",
    "fraud.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample = normal.sample(n=492) # cause 492 items are a fraud\n",
    "normal_sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    492\n",
       "0      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([normal_sample,fraud],ignore_index=True)\n",
    "new_data.head()\n",
    "new_data['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(\"Class\",axis = 1)\n",
    "y = new_data[\"Class\"]\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Logistic Regression========\n",
      "\n",
      " Accuracy: 0.97\n",
      "\n",
      " Precision: 0.9797979797979798\n",
      "\n",
      " Recall: 0.9897959183673469\n",
      "\n",
      " F1: 0.9847715736040609\n",
      "\n",
      "======Decision Tree Classifier========\n",
      "\n",
      " Accuracy: 0.98\n",
      "\n",
      " Precision: 0.98\n",
      "\n",
      " Recall: 1.0\n",
      "\n",
      " F1: 0.98989898989899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamiroscreti/anaconda3/envs/Portfolio/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\" : LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n======{name}========\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n Recall: {recall_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n F1: {f1_score(y_test,y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Class\",axis = 1)\n",
    "y = data[\"Class\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1    284315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "y_res.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Logistic Regression========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamiroscreti/anaconda3/envs/Portfolio/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.9989115550718023\n",
      "\n",
      " Precision: 0.7045454545454546\n",
      "\n",
      " Recall: 0.6326530612244898\n",
      "\n",
      " F1: 0.6666666666666666\n",
      "\n",
      "======Decision Tree Classifier========\n",
      "\n",
      " Accuracy: 0.9991046662687406\n",
      "\n",
      " Precision: 0.7155963302752294\n",
      "\n",
      " Recall: 0.7959183673469388\n",
      "\n",
      " F1: 0.7536231884057971\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state=42)\n",
    "classifier = {\n",
    "    \"Logistic Regression\" : LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n======{name}========\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n Recall: {recall_score(y_test,y_pred)}\")\n",
    "    print(f\"\\n F1: {f1_score(y_test,y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create a decision tree classifier object\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model on the training data\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "y_pred = dtc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_fraud_detection.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dtc,\"credit_card_fraud_detection.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"credit_card_fraud_detection.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamiroscreti/anaconda3/envs/Portfolio/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# i use first line of the csv as an example\n",
    "pred = model.predict([[0,-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud\n"
     ]
    }
   ],
   "source": [
    "if pred == 1:\n",
    "    print(\"Fraud\")\n",
    "else:\n",
    "    print(\"Not Fraud\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
